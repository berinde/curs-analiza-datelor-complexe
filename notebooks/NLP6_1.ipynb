{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B8a34m3HqcYz"
   },
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lhG9-IQSqPeb"
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N0Eq4B34rbnN",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9itgd1IysMQB"
   },
   "source": [
    "# Exemplu BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q1a_nSqIr1Qj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YShgAUb_sOay"
   },
   "outputs": [],
   "source": [
    "prop = 'This is a short sentece. This is another sentence'\n",
    "enc = tokenizer(prop)\n",
    "enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mo8u26TbsOdK"
   },
   "outputs": [],
   "source": [
    "print('Input IDs:', enc['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JolvFQJjsOfl"
   },
   "outputs": [],
   "source": [
    "print('Token Type IDs:', enc['token_type_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XghB9IY9tChj"
   },
   "outputs": [],
   "source": [
    "print('Attention Mask:', enc['attention_mask'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_UHMhcqatJkL"
   },
   "source": [
    "# Input IDs\n",
    "-> id-urile unice pentru fiecare token din modelul BERT pre-antrenat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h2fBMCdNtHLA"
   },
   "outputs": [],
   "source": [
    "print('Propozitia originala:', prop)\n",
    "print('ID-urile tokenurilor:', enc['input_ids'])\n",
    "print('ID-urile convertite inapoi in tokenuri:',\n",
    "      tokenizer.decode(enc['input_ids']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Miu6DNmDuEpm"
   },
   "source": [
    "# Token Type IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Smyo46FStlR_"
   },
   "outputs": [],
   "source": [
    "propa = 'Where is the library?'\n",
    "propb = 'Right to the left'\n",
    "\n",
    "enc2 = tokenizer(propa, propb)\n",
    "dec2 = tokenizer.decode(enc2['input_ids'])\n",
    "\n",
    "print(enc2)\n",
    "print(dec2)\n",
    "print(enc2['token_type_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "97BsA4SbvaBO"
   },
   "source": [
    "# Attention Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "83KnH8gSvbxL"
   },
   "outputs": [],
   "source": [
    "propa = 'Hello world'\n",
    "propa = 'Hello world again'\n",
    "\n",
    "enca = tokenizer(propa)\n",
    "encb = tokenizer(propb)\n",
    "\n",
    "print(enca)\n",
    "print(encb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jI_Z4tkWvolB"
   },
   "outputs": [],
   "source": [
    "exemplu = tokenizer([propa, propb], padding=True)\n",
    "print(exemplu['input_ids'])\n",
    "print(exemplu['token_type_ids'])\n",
    "print(exemplu['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UsPWeWrDv6JP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nlp_py_310",
   "language": "python",
   "name": "nlp_py_310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
