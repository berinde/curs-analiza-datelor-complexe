{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oZnaUKAV_Acn"
   },
   "source": [
    "# Ollama example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install package\n",
    "%pip install -U langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answers and questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OllamaLLM(model=\"llama3.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.invoke(\"what si langchain?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.invoke(\"tell me a joke\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = prompt | model\n",
    "\n",
    "response = chain.invoke({\"question\": \"What is LangChain?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OllamaLLM(model=\"llama3.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = ChatPromptTemplate([\n",
    "    (\"system\", \"You are a helpful AI customer support for a sports items store. Your name is {name}.\" ),\n",
    "    (\"human\", \"{user_input}\"),\n",
    "])\n",
    "\n",
    "prompt_value = {\n",
    "    \"name\": \"Bob\",\n",
    "    \"user_input\": \"What is your name and purpose?\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chain = template | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chain.invoke(prompt_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_value = {\n",
    "    \"name\": \"Bob\",\n",
    "    \"user_input\": \"What items do you have for football?\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chain.invoke(prompt_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YELP example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = OllamaLLM(model=\"llama3.2\")\n",
    "template = ChatPromptTemplate([\n",
    "    (\"system\", \"You are an AI agent the analyses the sentiment of sentences, if it's positive or negative, the vaue ranges should be in between -1 and 1, -1 negative, 0 neutral and 1 positive\"),\n",
    "    (\"human\", \"{user_input}\"),\n",
    "])\n",
    "\n",
    "prompt_value = {\n",
    "    \"user_input\": \"What is your name and purpose?\"\n",
    "    }\n",
    "\n",
    "chain = template | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    arrived reservation pm seat -PRON- right time ...\n",
       "1    receive amazing service food cook right waitre...\n",
       "2    breakfast delicious waitress awesome steak egg...\n",
       "3    eaten twice lunch first time french dip mom fi...\n",
       "4      awesome service great food buffy amazing server\n",
       "Name: text_prep, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://github.com/berinde/curs-analiza-datelor-complexe/blob/main/data/input/3.input_data_prepped_bow.csv?raw=True'\n",
    "reviews = pd.read_csv(url)\n",
    "reviews['text'] = reviews['text'].astype(str)\n",
    "reviews['text_prep'] = reviews['text_prep'].astype(str)\n",
    "reviews['text_prep_lim'] = reviews['text_prep_lim'].astype(str)\n",
    "reviews.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentece = reviews['text_prep'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'll analyze the sentiment of the sentence:\n",
      "\n",
      "\"arrived reservation pm seat -PRON- right time restaurant fairly loud first family dinner croed clear pm quiet food service outstanding reasonable price highly recommend mimi late dinner\"\n",
      "\n",
      "The sentiment score for this sentence is: 0.95 (positive)\n",
      "\n",
      "Here's a breakdown of my reasoning:\n",
      "\n",
      "* The phrase \"right time\" suggests that the reservation was convenient.\n",
      "* The word \"fairly\" before \"loud\" indicates that it wasn't extremely loud, but still noticeable.\n",
      "* The use of \"first\" and \"family dinner\" implies a positive experience.\n",
      "* The phrase \"food service outstanding\" reinforces this positivity.\n",
      "* The words \"reasonable price\" also suggest a positive sentiment.\n",
      "* The final sentence \"highly recommend mimi late dinner\" is a strong endorsement.\n",
      "\n",
      "Overall, the overall tone of the message is overwhelmingly positive.\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({\"user_input\":sentece}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rest_id</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>char_count</th>\n",
       "      <th>positive</th>\n",
       "      <th>text_prep</th>\n",
       "      <th>text_prep_tokens</th>\n",
       "      <th>word_len_prep</th>\n",
       "      <th>text_prep_lim</th>\n",
       "      <th>text_prep_lim_tokens</th>\n",
       "      <th>word_len_prep_lim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yGMCl0vYigshkXiZFIDTNw</td>\n",
       "      <td>We arrived for our reservation at 7:15pm.  The...</td>\n",
       "      <td>4</td>\n",
       "      <td>302</td>\n",
       "      <td>1</td>\n",
       "      <td>arrived reservation pm seat -PRON- right time ...</td>\n",
       "      <td>['arrived', 'reservation', 'pm', 'seat', '-PRO...</td>\n",
       "      <td>27</td>\n",
       "      <td>arrived reservation pm seat right time restura...</td>\n",
       "      <td>['arrived', 'reservation', 'pm', 'seat', 'righ...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yGMCl0vYigshkXiZFIDTNw</td>\n",
       "      <td>We received amazing service again. The food wa...</td>\n",
       "      <td>5</td>\n",
       "      <td>111</td>\n",
       "      <td>1</td>\n",
       "      <td>receive amazing service food cook right waitre...</td>\n",
       "      <td>['receive', 'amazing', 'service', 'food', 'coo...</td>\n",
       "      <td>10</td>\n",
       "      <td>receive amazing service food cook right waitre...</td>\n",
       "      <td>['receive', 'amazing', 'service', 'food', 'coo...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  rest_id                                               text  \\\n",
       "0  yGMCl0vYigshkXiZFIDTNw  We arrived for our reservation at 7:15pm.  The...   \n",
       "1  yGMCl0vYigshkXiZFIDTNw  We received amazing service again. The food wa...   \n",
       "\n",
       "   rating  char_count  positive  \\\n",
       "0       4         302         1   \n",
       "1       5         111         1   \n",
       "\n",
       "                                           text_prep  \\\n",
       "0  arrived reservation pm seat -PRON- right time ...   \n",
       "1  receive amazing service food cook right waitre...   \n",
       "\n",
       "                                    text_prep_tokens  word_len_prep  \\\n",
       "0  ['arrived', 'reservation', 'pm', 'seat', '-PRO...             27   \n",
       "1  ['receive', 'amazing', 'service', 'food', 'coo...             10   \n",
       "\n",
       "                                       text_prep_lim  \\\n",
       "0  arrived reservation pm seat right time restura...   \n",
       "1  receive amazing service food cook right waitre...   \n",
       "\n",
       "                                text_prep_lim_tokens  word_len_prep_lim  \n",
       "0  ['arrived', 'reservation', 'pm', 'seat', 'righ...                 25  \n",
       "1  ['receive', 'amazing', 'service', 'food', 'coo...                  9  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews['afinn_score_tp'] = reviews['text_prep'][0:5].apply(lambda x: Afinn().score(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anthropic agent example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://python.langchain.com/docs/tutorials/agents/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U langchain-community langgraph langchain-anthropic tavily-python langgraph-checkpoint-sqlite\n",
    "!pip install -U langchain-community tavily-python\n",
    "!pip install -U langchain-anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"\"\n",
    "os.environ[\"ANTHROPIC_API_KEY\"]=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fv4wU1QT_xt9"
   },
   "outputs": [],
   "source": [
    "# Import relevant functionality\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import create_react_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q1fpcJicASJr"
   },
   "source": [
    "## Create the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://python.langchain.com/docs/tutorials/agents/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kzrySSAUALdS"
   },
   "outputs": [],
   "source": [
    "memory = MemorySaver()\n",
    "model = ChatAnthropic(model_name=\"claude-3-sonnet-20240229\")\n",
    "search = TavilySearchResults(max_results=2)\n",
    "tools = [search]\n",
    "agent_executor = create_react_agent(model, tools, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the agent\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "for step in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"hi im bob! and i live in sf\")]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"whats the weather where I live?\")]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nlp_py_310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
